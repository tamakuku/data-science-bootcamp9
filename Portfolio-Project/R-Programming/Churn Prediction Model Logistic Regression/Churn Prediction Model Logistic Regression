
Link >>> https://posit.cloud/spaces/456340/content/7611104

### use Logistic Regression Model

install.packages("tidyverse") # Install tidyverse package for data manipulation
install.packages("caret") # Install caret package for supervised learning

library(tidyverse) # Load tidyverse package
library(caret) # Load caret package for supervised learning

#### Use churn.csv to build a model with the glm method using a 4-step basic ML workflow

## Read churn.csv file and return it into a dataframe
churn_df <- read.csv("churn.csv")
## View the dataframe
churn_df


### Step 1: Split data into Train (80%) & Test (20%)
## Build split data template
set.seed(42) ## Lock random sampling for reproducibility

n <- nrow(churn_df) ## Count the number of samples

train_id <- sample(1:n, size = 0.8 * n) ## Randomly sample 80% of the data for training

train_df <- churn_df[train_id, ] ## Training data
test_df <- churn_df[-train_id, ] ## Testing data

return(list(train_df, test_df)) ## Return the split data as a list

## Create a function to split data
train_test_split <- function(data) {
  set.seed(42)
  n <- nrow(data)
  train_id <- sample(1:n, size = 0.8 * n)
  train_df <- data[train_id, ]
  test_df <- data[-train_id, ]
  return(list(train_df, test_df))
}

## Use the split data function
train_test_split(churn_df)
## Return split data into a dataframe
preb_split_df <- train_test_split(churn_df)

## Preview split data: train and test sets
preb_split_df[[1]] ## Training data
preb_split_df[[2]] ## Testing data


### Step 2: Train the model using train() function with 4 features and K-fold Re-sampling (K=10)
## Build K-fold control value
ctrl_kfold <- trainControl(method = "CV", number = 10)

## Train the model
train_model <- train(churn ~ totaldayminutes + totaldaycalls + totaldaycharge + numbercustomerservicecalls,
                     data = churn_df,
                     method = "glm",
                     trControl = ctrl_kfold)
## Display the trained model
train_model


### Step 3: Score the model by predicting test data
## Predict test data
predict_test <- predict(train_model, newdata = preb_split_df[[2]])

## Display predictions
predict_test


### Step 4: Evaluate the model by calculating accuracy from test data
## If using method = "lm", use error metrics (MAE, RMSE)
## If using method = "glm", use accuracy

## Compare Train vs Test model
## Create actual test data
actual_test <- preb_split_df[[2]]$churn
## Preview actual test data
actual_test

## Calculate accuracy: mean(predict test data == actual test data)
acc_test_model <- mean(actual_test == predict_test)

### End by comparing the accuracy of the Train vs Test model
train_model

print(acc_test_model) ## Display the accuracy of the test model

